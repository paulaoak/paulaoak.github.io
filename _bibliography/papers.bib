@misc{corderoencinar2025samplingbyaveraging,
    title = {Sampling by averaging: A multiscale approach to score estimation},
    author = {Paula Cordero-Encinar and Andrew Duncan and Sebastian Reich and Deniz Akyildiz},
    year = 2025,
    abbr = {arXiv},
    abstract = {We introduce a novel framework for efficient sampling from complex, unnormalised target distributions by exploiting multiscale dynamics. Traditional score-based sampling methods either rely on learned approximations of the score function or involve computationally expensive nested Markov chain Monte Carlo (MCMC) loops. In contrast, the proposed approach leverages stochastic averaging within a slow-fast system of stochastic differential equations (SDEs) to estimate intermediate scores along a diffusion path without training or inner-loop MCMC. Two algorithms are developed under this framework: MultALMC, which uses multiscale annealed Langevin dynamics, and MultCDiff, based on multiscale controlled diffusions for the reverse-time Ornstein-Uhlenbeck process. Both overdamped and underdamped variants are considered, with theoretical guarantees of convergence to the desired diffusion path. The framework is extended to handle heavy-tailed target distributions using Student's t-based noise models and tailored fast-process dynamics. Empirical results across synthetic and real-world benchmarks, including multimodal and high-dimensional distributions, demonstrate that the proposed methods are competitive with existing samplers in terms of accuracy and efficiency, without the need for learned models.},
    pdf = {https://arxiv.org/pdf/2508.15069},
    selected = {true},
    code = {https://github.com/paulaoak/sampling_by_averaging}
}

@misc{corderoencinar2025pipla,
    title = {Proximal Interacting Particle Langevin Algorithms},
    author = {Paula Cordero-Encinar and Francesca Crucinio and Deniz Akyildiz},
    year = 2025,
    journal = {Conference on Uncertainty in Artificial Intelligence (UAI)},
    abbr = {UAI},
    abstract = {We introduce a class of algorithms, termed Proximal Interacting Particle Langevin Algorithms (PIPLA), for inference and learning in latent variable models whose joint probability density is non-differentiable. Leveraging proximal Markov chain Monte Carlo (MCMC) techniques and the recently introduced interacting particle Langevin algorithm (IPLA), we propose several variants within the novel proximal IPLA family, tailored to the problem of estimating parameters in a non-differentiable statistical model. We prove nonasymptotic bounds for the parameter estimates produced by multiple algorithms in the strongly log-concave setting and provide comprehensive numerical experiments on various models to demonstrate the effectiveness of the proposed methods. In particular, we demonstrate the utility of the proposed family of algorithms on a toy hierarchical example where our assumptions can be checked, as well as on the problems of sparse Bayesian logistic regression, sparse Bayesian neural network, and sparse matrix completion. Our theory and experiments together show that PIPLA family can be the de facto choice for parameter estimation problems in latent variable models for non-differentiable models.},
    pdf = {https://arxiv.org/pdf/2406.14292},
    code = {https://github.com/paulaoak/proximal-ipla},
    slides = {https://docs.google.com/presentation/d/1O4l2k-0b_jMFPI4TqKj_2kABQfi3_y5W5je_XxrnYq0/edit?usp=sharing},
    award = {This paper recieved the best student paper award and was selected as an oral at the conference.},
    award_name = {Oral and Best Student Paper},
    selected = {true}
}

@misc{corderoencinar2025annealedlangevin,
    title = {Non-asymptotic Analysis of Diffusion Annealed Langevin Monte Carlo for Generative Modelling},
    author = {Paula Cordero-Encinar and Deniz Akyildiz and Andrew Duncan},
    year = 2025,
    journal = {arXiv},
    abbr = {arXiv},
    abstract = {We investigate the theoretical properties of general diffusion (interpolation) paths and their Langevin Monte Carlo implementation, referred to as diffusion annealed Langevin Monte Carlo (DALMC), under weak conditions on the data distribution. Specifically, we analyse and provide non-asymptotic error bounds for the annealed Langevin dynamics where the path of distributions is defined as Gaussian convolutions of the data distribution as in diffusion models. We then extend our results to recently proposed heavy-tailed (Student's t) diffusion paths, demonstrating their theoretical properties for heavy-tailed data distributions for the first time. Our analysis provides theoretical guarantees for a class of score-based generative models that interpolate between a simple distribution (Gaussian or Student's t) and the data distribution in finite time. This approach offers a broader perspective compared to standard score-based diffusion approaches, which are typically based on a forward Ornstein-Uhlenbeck (OU) noising process.},
    pdf = {https://arxiv.org/pdf/2502.09306},
    slides = {gradients_flow_RSS_slides.pdf},
    selected = {true} 
}


@misc{corderoencinar2025sensor,
    title = {Deep Optimal Sensor Placement for Black Box Stochastic Simulations},
    author = {Paula Cordero-Encinar and Tobias Schr{\"o}der and Peter Yatsyshin and Andrew Duncan},
    year = 2025,
    journal = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
    abbr = {AISTATS},
    abstract = {Selecting cost-effective optimal sensor configurations for subsequent inference of parameters in black-box stochastic systems faces significant computational barriers. We propose a novel and robust approach, modelling the joint distribution over input parameters and solution with a joint energy-based model, trained on simulation data. Unlike existing simulation-based inference approaches, which must be tied to a specific set of point evaluations, we learn a functional representation of parameters and solution. This is used as a resolution-independent plug-and-play surrogate for the joint distribution, which can be conditioned over any set of points, permitting an efficient approach to sensor placement. We demonstrate the validity of our framework on a variety of stochastic problems, showing that our method provides highly informative sensor locations at a lower computational cost compared to conventional approaches.},
    pdf = {https://arxiv.org/pdf/2410.12036},
    slides = {paula_cordero_encinar_glasgow_stats_seminar.pdf},
    selected = {true}
}

@misc{corderoencinar2024optimal,
    title = {Optimal Experimental Design for Bayesian Inverse Problems using Energy-Based Couplings},
    author = {Paula Cordero-Encinar and Tobias Schr{\"o}der and Andrew Duncan},
    year = 2024,
    journal = {ICLR 2024 Workshop on AI4DifferentialEquations In Science},
    abbr = {AI4DiffEq @ICLR},
    selected = {false}
}


@misc{corderoencinar2021quantum,
    title = {Digital quantum simulation of beam splitters and squeezing with IBM quantum computers},
    author = {Paula Cordero-Encinar and Tobias Schr{\"o}der and Andrew Duncan},
    year = 2021,
    journal = {Phys. Rev. A},
    abbr = {Phys. Rev. A},
    pdf = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.104.052609},
    selected = {false}
}